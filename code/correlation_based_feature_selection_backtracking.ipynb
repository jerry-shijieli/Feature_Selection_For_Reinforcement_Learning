{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import MDP_function as mf\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import scipy.stats as stats\n",
    "import random as rnd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in all original data set\n",
    "data_file = \"MDP_Original_data.csv\"\n",
    "original_data = pd.read_csv(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# select all features from the original dataset and get features names as feature space indexes\n",
    "feature_data = original_data.loc[:, 'Interaction':'CurrPro_medianProbTime']\n",
    "feature_space = feature_data.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "def feature_discretization(feature_data, maxLevel=2): \n",
    "    # discretize continuous feature values into integers of no more than max levels\n",
    "    isFloat = any(map(lambda x: isinstance(x, float), feature_data)) # check if it contain float type\n",
    "    if not isFloat:\n",
    "        isOverLevel = len(feature_data.unique())>maxLevel # check if it is within max levels\n",
    "    if isFloat or isOverLevel: # discretize and reduce levels using median\n",
    "        median = feature_data.median()\n",
    "        feature_vals = map(lambda x: 0 if x<=median else 1, feature_data)\n",
    "        feature_data = pd.Series(feature_vals, dtype=int)\n",
    "    return feature_data\n",
    "\n",
    "def compute_correlation(dataset, feature_set, feature):\n",
    "#     corr_sum = 0\n",
    "#     for ft in feature_set:\n",
    "#         corr, p_val = stats.pearsonr(dataset[ft], dataset[feature])\n",
    "#         corr_sum += corr\n",
    "#     return corr_sum\n",
    "    return rnd.random()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialize parameters and data structures for correlation-based feature selection algorithm\n",
    "MAX_NUM_OF_FEATURES = 2\n",
    "ECR_list = list()\n",
    "optimal_feature_set = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# discretization feature values by median\n",
    "all_data_discretized = original_data.loc[:, \"student\":\"reward\"]\n",
    "for i, ft in enumerate(feature_space):\n",
    "    ft_data = original_data.loc[:, ft]\n",
    "    all_data_discretized[ft] = feature_discretization(ft_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialization to find the best feature with max ECR\n",
    "for ft in feature_space:\n",
    "    selected_features = [ft]\n",
    "#     try:\n",
    "#         ECR_list.append(mf.compute_ECR(all_data_discretized, selected_feature))\n",
    "#     except:\n",
    "    ECR_list.append(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Interaction']\n"
     ]
    }
   ],
   "source": [
    "# initialize the optimal feature set with feature of highest ECR\n",
    "optimal_feature_set.append(feature_space[ECR_list.index(max(ECR_list))])\n",
    "print(optimal_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['cumul_deletedApp', 4.0173507069031302]]\n",
      "[['cumul_deletedApp', 4.0173507069031302], ['difficultProblemCountWE', 17.938717295288942]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jerry/anaconda/lib/python2.7/site-packages/pandas/core/indexing.py:477: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "# feature selection iterations\n",
    "while (len(optimal_feature_set) < MAX_NUM_OF_FEATURES):\n",
    "    #print len(optimal_feature_set)\n",
    "    remain_feature_space = list(set(feature_space) - set(optimal_feature_set)) # features not in optimal feature set\n",
    "    corr_list = list() # correlation between new feature and optimal feature set\n",
    "    for i,ft in enumerate(remain_feature_space):\n",
    "        corr_list.append([ft, compute_correlation(all_data_discretized, optimal_feature_set, ft)])\n",
    "    topK = 2 # choose top-K candidate features based on feature similarity metrics\n",
    "    top_features = map(lambda x: x[0], sorted(corr_list, key=lambda x: x[1], reverse=False)[:topK])\n",
    "    ECR_list = list() # ECR values of optimal feature set with new candidate feature\n",
    "    for ft in top_features:\n",
    "        selected_feature = list(optimal_feature_set)\n",
    "        selected_feature.append(ft) # combine candidate feature to optimal feature set\n",
    "        ECR_with_ft_added = mf.compute_ECR(all_data_discretized, selected_feature)\n",
    "        ECR_list.append([ft, ECR_with_ft_added])\n",
    "        print \"Candidate feature: \"+ ft +\" --> ECR value:\"+ str(ECR_with_ft_added)\n",
    "    best_next_feature, bestECR = sorted(ECR_list, key=lambda x: x[1], reverse=True)[0]\n",
    "    optimal_feature_set.append(best_next_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Interaction', 'difficultProblemCountWE']\n"
     ]
    }
   ],
   "source": [
    "print optimal_feature_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Policy: \n",
      "state -> action, value-function\n",
      "1:0 -> WE, 18.1849003631\n",
      "0:0 -> WE, 17.6456422146\n",
      "0:1 -> PS, 21.176049136\n",
      "1:1 -> WE, 18.9090058985\n",
      "ECR value: 17.9387172953\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17.938717295288942"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mf.induce_policy_MDP2(all_data_discretized, optimal_feature_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
